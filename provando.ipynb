{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disi/ml/mlvenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import wandb\n",
    "import yaml\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from utils.logger import *\n",
    "from utils.models_init import *\n",
    "from utils.training import * \n",
    "from utils.optimizers import *\n",
    "from utils.custom_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/disi/ml/intromlproject/config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "config = config['config']\n",
    "config['data_dir'] = config['data_dir'].format(root=config['root'], img_folder=config['img_folder'])\n",
    "config['save_dir'] = config['save_dir'].format(root=config['root'], model_name=config['model_name'], img_folder=config['img_folder'])\n",
    "if config['checkpoint'] is not None:\n",
    "    config['checkpoint'] = config['checkpoint'].format(root=config['root'])\n",
    "config['device'] = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "config['project_name'] = config['project_name'].format(model_name=config['model_name'])\n",
    "config['dataset_name'] = config['dataset_name'].format(img_folder=config['img_folder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((config['image_size'], config['image_size'])),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=config['mean'], std=config['std'])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root=os.path.join(config['data_dir'], 'train'), transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(root=os.path.join(config['data_dir'], 'val'), transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch of inputs: torch.Size([64, 3, 224, 224])\n",
      "First batch of labels: torch.Size([64])\n",
      "DataLoader loaded correctly.\n"
     ]
    }
   ],
   "source": [
    "# Function to check DataLoader\n",
    "def check_dataloader(loader):\n",
    "    try:\n",
    "        for i, (inputs, labels) in enumerate(loader):\n",
    "            if i == 0:  # Just check the first batch to keep it simple\n",
    "                print(\"First batch of inputs:\", inputs.shape)\n",
    "                print(\"First batch of labels:\", labels.shape)\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(\"Error during loading data:\", e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Check DataLoader\n",
    "if check_dataloader(train_loader):\n",
    "    print(\"DataLoader loaded correctly.\")\n",
    "else:\n",
    "    print(\"DataLoader has issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disi/ml/mlvenv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/disi/ml/mlvenv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_loader.dataset.classes)\n",
    "model = init_model(config['model_name'], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimize only the parameters that require gradients\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 3, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "# Define your data directory\n",
    "data_dir = '/home/disi/ml/datasets/aircraft'\n",
    "\n",
    "# Optionally, define transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "datasets = {\n",
    "    x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "    for x in ['train', 'val']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 3334, 'val': 3333}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the size of each dataset\n",
    "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val']}\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "for inputs, labels in train_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "for inputs, labels in val_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is loaded on: cuda:0\n",
      "features.conv0.weight is on cuda:0\n",
      "features.norm0.weight is on cuda:0\n",
      "features.norm0.bias is on cuda:0\n",
      "features.denseblock1.denselayer1.norm1.weight is on cuda:0\n",
      "features.denseblock1.denselayer1.norm1.bias is on cuda:0\n",
      "features.denseblock1.denselayer1.conv1.weight is on cuda:0\n",
      "features.denseblock1.denselayer1.norm2.weight is on cuda:0\n",
      "features.denseblock1.denselayer1.norm2.bias is on cuda:0\n",
      "features.denseblock1.denselayer1.conv2.weight is on cuda:0\n",
      "features.denseblock1.denselayer2.norm1.weight is on cuda:0\n",
      "features.denseblock1.denselayer2.norm1.bias is on cuda:0\n",
      "features.denseblock1.denselayer2.conv1.weight is on cuda:0\n",
      "features.denseblock1.denselayer2.norm2.weight is on cuda:0\n",
      "features.denseblock1.denselayer2.norm2.bias is on cuda:0\n",
      "features.denseblock1.denselayer2.conv2.weight is on cuda:0\n",
      "features.denseblock1.denselayer3.norm1.weight is on cuda:0\n",
      "features.denseblock1.denselayer3.norm1.bias is on cuda:0\n",
      "features.denseblock1.denselayer3.conv1.weight is on cuda:0\n",
      "features.denseblock1.denselayer3.norm2.weight is on cuda:0\n",
      "features.denseblock1.denselayer3.norm2.bias is on cuda:0\n",
      "features.denseblock1.denselayer3.conv2.weight is on cuda:0\n",
      "features.denseblock1.denselayer4.norm1.weight is on cuda:0\n",
      "features.denseblock1.denselayer4.norm1.bias is on cuda:0\n",
      "features.denseblock1.denselayer4.conv1.weight is on cuda:0\n",
      "features.denseblock1.denselayer4.norm2.weight is on cuda:0\n",
      "features.denseblock1.denselayer4.norm2.bias is on cuda:0\n",
      "features.denseblock1.denselayer4.conv2.weight is on cuda:0\n",
      "features.denseblock1.denselayer5.norm1.weight is on cuda:0\n",
      "features.denseblock1.denselayer5.norm1.bias is on cuda:0\n",
      "features.denseblock1.denselayer5.conv1.weight is on cuda:0\n",
      "features.denseblock1.denselayer5.norm2.weight is on cuda:0\n",
      "features.denseblock1.denselayer5.norm2.bias is on cuda:0\n",
      "features.denseblock1.denselayer5.conv2.weight is on cuda:0\n",
      "features.denseblock1.denselayer6.norm1.weight is on cuda:0\n",
      "features.denseblock1.denselayer6.norm1.bias is on cuda:0\n",
      "features.denseblock1.denselayer6.conv1.weight is on cuda:0\n",
      "features.denseblock1.denselayer6.norm2.weight is on cuda:0\n",
      "features.denseblock1.denselayer6.norm2.bias is on cuda:0\n",
      "features.denseblock1.denselayer6.conv2.weight is on cuda:0\n",
      "features.transition1.norm.weight is on cuda:0\n",
      "features.transition1.norm.bias is on cuda:0\n",
      "features.transition1.conv.weight is on cuda:0\n",
      "features.denseblock2.denselayer1.norm1.weight is on cuda:0\n",
      "features.denseblock2.denselayer1.norm1.bias is on cuda:0\n",
      "features.denseblock2.denselayer1.conv1.weight is on cuda:0\n",
      "features.denseblock2.denselayer1.norm2.weight is on cuda:0\n",
      "features.denseblock2.denselayer1.norm2.bias is on cuda:0\n",
      "features.denseblock2.denselayer1.conv2.weight is on cuda:0\n",
      "features.denseblock2.denselayer2.norm1.weight is on cuda:0\n",
      "features.denseblock2.denselayer2.norm1.bias is on cuda:0\n",
      "features.denseblock2.denselayer2.conv1.weight is on cuda:0\n",
      "features.denseblock2.denselayer2.norm2.weight is on cuda:0\n",
      "features.denseblock2.denselayer2.norm2.bias is on cuda:0\n",
      "features.denseblock2.denselayer2.conv2.weight is on cuda:0\n",
      "features.denseblock2.denselayer3.norm1.weight is on cuda:0\n",
      "features.denseblock2.denselayer3.norm1.bias is on cuda:0\n",
      "features.denseblock2.denselayer3.conv1.weight is on cuda:0\n",
      "features.denseblock2.denselayer3.norm2.weight is on cuda:0\n",
      "features.denseblock2.denselayer3.norm2.bias is on cuda:0\n",
      "features.denseblock2.denselayer3.conv2.weight is on cuda:0\n",
      "features.denseblock2.denselayer4.norm1.weight is on cuda:0\n",
      "features.denseblock2.denselayer4.norm1.bias is on cuda:0\n",
      "features.denseblock2.denselayer4.conv1.weight is on cuda:0\n",
      "features.denseblock2.denselayer4.norm2.weight is on cuda:0\n",
      "features.denseblock2.denselayer4.norm2.bias is on cuda:0\n",
      "features.denseblock2.denselayer4.conv2.weight is on cuda:0\n",
      "features.denseblock2.denselayer5.norm1.weight is on cuda:0\n",
      "features.denseblock2.denselayer5.norm1.bias is on cuda:0\n",
      "features.denseblock2.denselayer5.conv1.weight is on cuda:0\n",
      "features.denseblock2.denselayer5.norm2.weight is on cuda:0\n",
      "features.denseblock2.denselayer5.norm2.bias is on cuda:0\n",
      "features.denseblock2.denselayer5.conv2.weight is on cuda:0\n",
      "features.denseblock2.denselayer6.norm1.weight is on cuda:0\n",
      "features.denseblock2.denselayer6.norm1.bias is on cuda:0\n",
      "features.denseblock2.denselayer6.conv1.weight is on cuda:0\n",
      "features.denseblock2.denselayer6.norm2.weight is on cuda:0\n",
      "features.denseblock2.denselayer6.norm2.bias is on cuda:0\n",
      "features.denseblock2.denselayer6.conv2.weight is on cuda:0\n",
      "features.denseblock2.denselayer7.norm1.weight is on cuda:0\n",
      "features.denseblock2.denselayer7.norm1.bias is on cuda:0\n",
      "features.denseblock2.denselayer7.conv1.weight is on cuda:0\n",
      "features.denseblock2.denselayer7.norm2.weight is on cuda:0\n",
      "features.denseblock2.denselayer7.norm2.bias is on cuda:0\n",
      "features.denseblock2.denselayer7.conv2.weight is on cuda:0\n",
      "features.denseblock2.denselayer8.norm1.weight is on cuda:0\n",
      "features.denseblock2.denselayer8.norm1.bias is on cuda:0\n",
      "features.denseblock2.denselayer8.conv1.weight is on cuda:0\n",
      "features.denseblock2.denselayer8.norm2.weight is on cuda:0\n",
      "features.denseblock2.denselayer8.norm2.bias is on cuda:0\n",
      "features.denseblock2.denselayer8.conv2.weight is on cuda:0\n",
      "features.denseblock2.denselayer9.norm1.weight is on cuda:0\n",
      "features.denseblock2.denselayer9.norm1.bias is on cuda:0\n",
      "features.denseblock2.denselayer9.conv1.weight is on cuda:0\n",
      "features.denseblock2.denselayer9.norm2.weight is on cuda:0\n",
      "features.denseblock2.denselayer9.norm2.bias is on cuda:0\n",
      "features.denseblock2.denselayer9.conv2.weight is on cuda:0\n",
      "features.denseblock2.denselayer10.norm1.weight is on cuda:0\n",
      "features.denseblock2.denselayer10.norm1.bias is on cuda:0\n",
      "features.denseblock2.denselayer10.conv1.weight is on cuda:0\n",
      "features.denseblock2.denselayer10.norm2.weight is on cuda:0\n",
      "features.denseblock2.denselayer10.norm2.bias is on cuda:0\n",
      "features.denseblock2.denselayer10.conv2.weight is on cuda:0\n",
      "features.denseblock2.denselayer11.norm1.weight is on cuda:0\n",
      "features.denseblock2.denselayer11.norm1.bias is on cuda:0\n",
      "features.denseblock2.denselayer11.conv1.weight is on cuda:0\n",
      "features.denseblock2.denselayer11.norm2.weight is on cuda:0\n",
      "features.denseblock2.denselayer11.norm2.bias is on cuda:0\n",
      "features.denseblock2.denselayer11.conv2.weight is on cuda:0\n",
      "features.denseblock2.denselayer12.norm1.weight is on cuda:0\n",
      "features.denseblock2.denselayer12.norm1.bias is on cuda:0\n",
      "features.denseblock2.denselayer12.conv1.weight is on cuda:0\n",
      "features.denseblock2.denselayer12.norm2.weight is on cuda:0\n",
      "features.denseblock2.denselayer12.norm2.bias is on cuda:0\n",
      "features.denseblock2.denselayer12.conv2.weight is on cuda:0\n",
      "features.transition2.norm.weight is on cuda:0\n",
      "features.transition2.norm.bias is on cuda:0\n",
      "features.transition2.conv.weight is on cuda:0\n",
      "features.denseblock3.denselayer1.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer1.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer1.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer1.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer1.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer1.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer2.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer2.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer2.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer2.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer2.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer2.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer3.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer3.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer3.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer3.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer3.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer3.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer4.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer4.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer4.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer4.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer4.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer4.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer5.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer5.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer5.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer5.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer5.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer5.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer6.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer6.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer6.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer6.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer6.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer6.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer7.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer7.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer7.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer7.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer7.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer7.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer8.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer8.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer8.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer8.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer8.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer8.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer9.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer9.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer9.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer9.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer9.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer9.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer10.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer10.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer10.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer10.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer10.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer10.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer11.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer11.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer11.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer11.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer11.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer11.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer12.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer12.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer12.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer12.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer12.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer12.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer13.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer13.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer13.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer13.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer13.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer13.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer14.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer14.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer14.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer14.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer14.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer14.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer15.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer15.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer15.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer15.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer15.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer15.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer16.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer16.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer16.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer16.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer16.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer16.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer17.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer17.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer17.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer17.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer17.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer17.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer18.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer18.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer18.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer18.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer18.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer18.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer19.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer19.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer19.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer19.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer19.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer19.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer20.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer20.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer20.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer20.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer20.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer20.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer21.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer21.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer21.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer21.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer21.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer21.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer22.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer22.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer22.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer22.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer22.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer22.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer23.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer23.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer23.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer23.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer23.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer23.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer24.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer24.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer24.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer24.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer24.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer24.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer25.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer25.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer25.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer25.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer25.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer25.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer26.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer26.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer26.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer26.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer26.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer26.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer27.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer27.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer27.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer27.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer27.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer27.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer28.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer28.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer28.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer28.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer28.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer28.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer29.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer29.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer29.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer29.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer29.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer29.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer30.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer30.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer30.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer30.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer30.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer30.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer31.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer31.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer31.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer31.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer31.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer31.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer32.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer32.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer32.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer32.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer32.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer32.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer33.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer33.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer33.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer33.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer33.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer33.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer34.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer34.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer34.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer34.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer34.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer34.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer35.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer35.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer35.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer35.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer35.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer35.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer36.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer36.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer36.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer36.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer36.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer36.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer37.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer37.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer37.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer37.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer37.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer37.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer38.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer38.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer38.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer38.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer38.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer38.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer39.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer39.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer39.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer39.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer39.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer39.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer40.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer40.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer40.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer40.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer40.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer40.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer41.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer41.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer41.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer41.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer41.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer41.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer42.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer42.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer42.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer42.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer42.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer42.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer43.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer43.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer43.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer43.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer43.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer43.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer44.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer44.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer44.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer44.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer44.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer44.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer45.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer45.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer45.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer45.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer45.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer45.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer46.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer46.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer46.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer46.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer46.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer46.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer47.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer47.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer47.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer47.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer47.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer47.conv2.weight is on cuda:0\n",
      "features.denseblock3.denselayer48.norm1.weight is on cuda:0\n",
      "features.denseblock3.denselayer48.norm1.bias is on cuda:0\n",
      "features.denseblock3.denselayer48.conv1.weight is on cuda:0\n",
      "features.denseblock3.denselayer48.norm2.weight is on cuda:0\n",
      "features.denseblock3.denselayer48.norm2.bias is on cuda:0\n",
      "features.denseblock3.denselayer48.conv2.weight is on cuda:0\n",
      "features.transition3.norm.weight is on cuda:0\n",
      "features.transition3.norm.bias is on cuda:0\n",
      "features.transition3.conv.weight is on cuda:0\n",
      "features.denseblock4.denselayer1.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer1.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer1.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer1.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer1.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer1.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer2.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer2.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer2.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer2.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer2.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer2.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer3.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer3.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer3.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer3.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer3.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer3.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer4.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer4.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer4.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer4.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer4.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer4.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer5.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer5.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer5.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer5.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer5.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer5.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer6.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer6.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer6.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer6.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer6.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer6.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer7.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer7.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer7.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer7.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer7.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer7.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer8.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer8.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer8.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer8.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer8.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer8.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer9.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer9.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer9.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer9.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer9.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer9.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer10.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer10.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer10.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer10.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer10.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer10.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer11.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer11.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer11.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer11.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer11.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer11.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer12.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer12.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer12.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer12.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer12.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer12.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer13.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer13.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer13.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer13.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer13.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer13.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer14.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer14.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer14.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer14.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer14.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer14.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer15.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer15.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer15.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer15.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer15.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer15.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer16.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer16.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer16.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer16.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer16.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer16.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer17.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer17.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer17.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer17.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer17.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer17.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer18.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer18.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer18.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer18.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer18.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer18.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer19.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer19.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer19.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer19.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer19.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer19.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer20.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer20.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer20.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer20.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer20.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer20.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer21.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer21.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer21.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer21.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer21.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer21.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer22.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer22.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer22.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer22.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer22.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer22.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer23.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer23.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer23.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer23.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer23.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer23.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer24.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer24.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer24.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer24.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer24.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer24.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer25.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer25.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer25.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer25.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer25.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer25.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer26.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer26.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer26.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer26.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer26.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer26.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer27.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer27.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer27.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer27.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer27.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer27.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer28.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer28.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer28.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer28.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer28.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer28.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer29.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer29.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer29.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer29.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer29.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer29.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer30.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer30.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer30.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer30.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer30.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer30.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer31.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer31.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer31.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer31.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer31.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer31.conv2.weight is on cuda:0\n",
      "features.denseblock4.denselayer32.norm1.weight is on cuda:0\n",
      "features.denseblock4.denselayer32.norm1.bias is on cuda:0\n",
      "features.denseblock4.denselayer32.conv1.weight is on cuda:0\n",
      "features.denseblock4.denselayer32.norm2.weight is on cuda:0\n",
      "features.denseblock4.denselayer32.norm2.bias is on cuda:0\n",
      "features.denseblock4.denselayer32.conv2.weight is on cuda:0\n",
      "features.norm5.weight is on cuda:0\n",
      "features.norm5.bias is on cuda:0\n",
      "classifier.weight is on cuda:0\n",
      "classifier.bias is on cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'model' is your neural network model\n",
    "first_param_device = next(model.parameters()).device\n",
    "print(f\"The model is loaded on: {first_param_device}\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name} is on {param.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlorenzo-chicco\u001b[0m (\u001b[33mlorenzochicco99\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/disi/ml/intromlproject/wandb/run-20240530_092914-kjc7bs41</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lorenzochicco99/vit_freeze_test/runs/kjc7bs41' target=\"_blank\">aircraft</a></strong> to <a href='https://wandb.ai/lorenzochicco99/vit_freeze_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lorenzochicco99/vit_freeze_test' target=\"_blank\">https://wandb.ai/lorenzochicco99/vit_freeze_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lorenzochicco99/vit_freeze_test/runs/kjc7bs41' target=\"_blank\">https://wandb.ai/lorenzochicco99/vit_freeze_test/runs/kjc7bs41</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/lorenzochicco99/vit_freeze_test/runs/kjc7bs41?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f75549ce6d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()  # @edit\n",
    "wandb.init(project=config['project_name'],\n",
    "name = config['dataset_name'],\n",
    "#name=f\"{config['model_name']}_{config['dataset_name']}_opt: {config['optimizer']}_batch_size: {config['batch_size']}_lr: {config['learning_rate']}\",\n",
    "config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "----------\n",
      "Entered train mode\n",
      "train Loss: 3.2182 Acc: 0.1956\n",
      "Entered val mode\n",
      "val Loss: 2.9834 Acc: 0.2373\n",
      "Epoch 2/11\n",
      "----------\n",
      "Entered train mode\n",
      "train Loss: 2.0459 Acc: 0.4049\n",
      "Entered val mode\n",
      "val Loss: 2.6404 Acc: 0.3042\n",
      "Epoch 3/11\n",
      "----------\n",
      "Entered train mode\n",
      "train Loss: 1.4728 Acc: 0.5630\n",
      "Entered val mode\n",
      "val Loss: 1.8426 Acc: 0.4584\n",
      "Epoch 4/11\n",
      "----------\n",
      "Entered train mode\n",
      "train Loss: 0.8998 Acc: 0.7579\n",
      "Entered val mode\n",
      "val Loss: 1.0055 Acc: 0.7276\n",
      "Epoch 5/11\n",
      "----------\n",
      "Entered train mode\n",
      "train Loss: 0.6465 Acc: 0.8326\n",
      "Entered val mode\n",
      "val Loss: 0.9072 Acc: 0.7435\n",
      "Epoch 6/11\n",
      "----------\n",
      "Entered train mode\n",
      "train Loss: 0.5391 Acc: 0.8737\n",
      "Entered val mode\n",
      "val Loss: 0.8298 Acc: 0.7672\n",
      "Epoch 7/11\n",
      "----------\n",
      "Entered train mode\n",
      "train Loss: 0.4479 Acc: 0.9010\n",
      "Entered val mode\n",
      "val Loss: 0.8141 Acc: 0.7699\n",
      "Epoch 8/11\n",
      "----------\n",
      "Entered train mode\n",
      "train Loss: 0.4234 Acc: 0.9115\n",
      "Entered val mode\n",
      "val Loss: 0.8038 Acc: 0.7768\n",
      "Epoch 9/11\n",
      "----------\n",
      "Entered train mode\n",
      "train Loss: 0.4096 Acc: 0.9184\n",
      "Entered val mode\n",
      "val Loss: 0.8032 Acc: 0.7699\n",
      "Epoch 10/11\n",
      "----------\n",
      "Entered train mode\n",
      "train Loss: 0.4005 Acc: 0.9205\n",
      "Entered val mode\n",
      "val Loss: 0.7913 Acc: 0.7822\n",
      "Epoch 11/11\n",
      "----------\n",
      "Entered train mode\n",
      "train Loss: 0.4102 Acc: 0.9199\n",
      "Entered val mode\n",
      "val Loss: 0.7942 Acc: 0.7825\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=25):\n",
    "    counter = 0\n",
    "    patience = 3\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                data_loader = train_loader\n",
    "                print(\"Entered train mode\")\n",
    "\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                data_loader = val_loader\n",
    "                print(\"Entered val mode\")\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            # Iterate over data\n",
    "            for inputs, labels in data_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                total_samples += inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / total_samples\n",
    "            epoch_acc = running_corrects.double() / total_samples\n",
    "\n",
    "            if phase == \"train\":\n",
    "                wandb.log({\n",
    "                \"train/loss\": epoch_loss,\n",
    "                \"train/accuracy\":epoch_acc,\n",
    "                \"epoch\": epoch\n",
    "                })\n",
    "            \n",
    "            else:\n",
    "                wandb.log({\n",
    "                \"val/loss\":epoch_loss,\n",
    "                \"val/accuracy\":epoch_acc,\n",
    "                \"epoch\": epoch})\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        if epoch_loss < best_val_loss:\n",
    "            counter = 0\n",
    "            best_val_loss = epoch_loss\n",
    "\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter > patience:\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    print('Training complete')\n",
    "    return model\n",
    "\n",
    "# Execute the training function\n",
    "model_ft = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=11)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
