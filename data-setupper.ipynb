{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_setupper.downloader import *\n",
    "from utils.data_setupper.dataset_reader import *\n",
    "from utils.data_setupper.extractors import *\n",
    "from utils.data_setupper.augmentation import *\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook usage\n",
    "This notebook is used to streamline as much as possible the data setup for the project. We have trained models on data downloaded from the internet \n",
    "as well as those already implemented in pytorch. For the latter, there are function already implemented in the main.py since we can work directly with the object instantiated by the library.\n",
    "\n",
    "This notebook will help you set up the data in the correct directory structure when downloading from Kaggle or the Internet.\n",
    "It will be used to download the data, extract it, and set it up in the correct directory structure.\n",
    "If you want to work using datasets preloaded in Torch or timm, you can skip this notebook.\n",
    "\n",
    "Everything that needs to be edited is marked with \"@edit\". It is procedural, therefore do not skip steps and go one cell at the time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/wenewone/cub2002011\n",
      "Kaggle Dataset downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# manually edit the three following lines, save the dataset wherever you wish, but the \"datasets\" folder is recommended\n",
    "# make sure to use the absolute path, not relative\n",
    "# @edit\n",
    "#dataset_url = \"https://www.kaggle.com/datasets/prasanshasatpathy/soil-types\"\n",
    "dataset_url = \"https://www.kaggle.com/datasets/wenewone/cub2002011\"\n",
    "# @edit\n",
    "root = \"/home/disi/ml/datasets\"\n",
    "download_dataset_kaggle(dataset_url, root)\n",
    "# @edit extract zip if needed\n",
    "#extract_tgz(f\"{dataset_url}/datasets.tar.gz\", root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dataset from a url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @edit\n",
    "dataset_url = \"https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\"\n",
    "root = \"/home/disi/ml/datasets\"\n",
    "i = download_dataset(dataset_url, root)\n",
    "# Manually move it in the datasets folder if you do not need to unzip it, otherwhise extracting it with the following function\n",
    "# will do it for you\n",
    "# @edit\n",
    "extract_tgz(f\"{dataset_url}/datasets.tar.gz\", root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment the dataset (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @edit\n",
    "# make sure to add a / in front of the folder name \n",
    "dataset_folder = root + \"/flowers\"\n",
    "image_generator =  setup_data_generator(rotation_range=40,\n",
    "                                        width_shift_range=0.2, \n",
    "                                        height_shift_range=0.2,\n",
    "                                        shear_range=0.2, \n",
    "                                        zoom_range=0.2, \n",
    "                                        horizontal_flip=True, \n",
    "                                        fill_mode='nearest')\n",
    "\n",
    "create_train_val_test_folders(dataset_folder, train_size=0.7, val_size=0.15, test_size=0.15)\n",
    "cleanup(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path  = dataset_folder + \"/train\"\n",
    "train_generator = load_data_from_directory(directory_path, target_size=(300,300), batch_size=32)\n",
    "n_of_batches = 50\n",
    "\n",
    "#TODO write how the number of batches infuences the actual amount of images generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images, labels) in enumerate(train_generator):\n",
    "    if i >= n_of_batches:  # Stop after saving images from 50 batches\n",
    "        break\n",
    "    save_augmented_images(images, labels, directory_path, train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test-Val-Split\n",
    "If you augmented the images you are good to go, the dataset is ready to be used in the main function. Otherwhise edit and execute the following block of code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @edit\n",
    "# make sure to add a / in front of the folder name \n",
    "root = \"/home/disi/ml/datasets\"\n",
    "folder_target = f\"{root}/CUB_200_2011/images\"\n",
    "dataset_folder = folder_target #+ \"/jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_train_val_test_folders(dataset_folder, train_size=0.7, val_size=0.15, test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last step\n",
    "Once you reach the train-test-val configuration, run this final function to create a folder named as you wish that will contain train-test-val. This will be our root in the main.py. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @edit\n",
    "location = root\n",
    "newfolder_name = ''\n",
    "train_folder = f'{location}/train/'\n",
    "val_folder = f'{location}/val/'\n",
    "test_folder = f'{location}/test/'\n",
    "final_structure(location, newfolder_name, train_folder, val_folder, test_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
