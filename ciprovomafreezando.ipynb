{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disi/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read dataset successfully\n",
      "Data loader successfully\n"
     ]
    }
   ],
   "source": [
    "from intromlproject.utils.read_dataset import read_dataset, transform_dataset, get_data_loader\n",
    "\n",
    "train_data, val_data, test_data = read_dataset(\"intromlproject/cub\", transform_dataset())\n",
    "train_loader, val_loader, test_loader = get_data_loader(train_data, val_data, test_data, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    'train': len(train_loader.dataset),\n",
    "    'val': len(val_loader.dataset),\n",
    "    'test': len(test_loader.dataset)\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001.Black_footed_Albatross', '002.Laysan_Albatross', '003.Sooty_Albatross', '004.Groove_billed_Ani', '005.Crested_Auklet', '006.Least_Auklet', '007.Parakeet_Auklet', '008.Rhinoceros_Auklet', '009.Brewer_Blackbird', '010.Red_winged_Blackbird', '011.Rusty_Blackbird', '012.Yellow_headed_Blackbird', '013.Bobolink', '014.Indigo_Bunting', '015.Lazuli_Bunting', '016.Painted_Bunting', '017.Cardinal', '018.Spotted_Catbird', '019.Gray_Catbird', '020.Yellow_breasted_Chat', '021.Eastern_Towhee', '022.Chuck_will_Widow', '023.Brandt_Cormorant', '024.Red_faced_Cormorant', '025.Pelagic_Cormorant', '026.Bronzed_Cowbird', '027.Shiny_Cowbird', '028.Brown_Creeper', '029.American_Crow', '030.Fish_Crow', '031.Black_billed_Cuckoo', '032.Mangrove_Cuckoo', '033.Yellow_billed_Cuckoo', '034.Gray_crowned_Rosy_Finch', '035.Purple_Finch', '036.Northern_Flicker', '037.Acadian_Flycatcher', '038.Great_Crested_Flycatcher', '039.Least_Flycatcher', '040.Olive_sided_Flycatcher', '041.Scissor_tailed_Flycatcher', '042.Vermilion_Flycatcher', '043.Yellow_bellied_Flycatcher', '044.Frigatebird', '045.Northern_Fulmar', '046.Gadwall', '047.American_Goldfinch', '048.European_Goldfinch', '049.Boat_tailed_Grackle', '050.Eared_Grebe', '051.Horned_Grebe', '052.Pied_billed_Grebe', '053.Western_Grebe', '054.Blue_Grosbeak', '055.Evening_Grosbeak', '056.Pine_Grosbeak', '057.Rose_breasted_Grosbeak', '058.Pigeon_Guillemot', '059.California_Gull', '060.Glaucous_winged_Gull', '061.Heermann_Gull', '062.Herring_Gull', '063.Ivory_Gull', '064.Ring_billed_Gull', '065.Slaty_backed_Gull', '066.Western_Gull', '067.Anna_Hummingbird', '068.Ruby_throated_Hummingbird', '069.Rufous_Hummingbird', '070.Green_Violetear', '071.Long_tailed_Jaeger', '072.Pomarine_Jaeger', '073.Blue_Jay', '074.Florida_Jay', '075.Green_Jay', '076.Dark_eyed_Junco', '077.Tropical_Kingbird', '078.Gray_Kingbird', '079.Belted_Kingfisher', '080.Green_Kingfisher', '081.Pied_Kingfisher', '082.Ringed_Kingfisher', '083.White_breasted_Kingfisher', '084.Red_legged_Kittiwake', '085.Horned_Lark', '086.Pacific_Loon', '087.Mallard', '088.Western_Meadowlark', '089.Hooded_Merganser', '090.Red_breasted_Merganser', '091.Mockingbird', '092.Nighthawk', '093.Clark_Nutcracker', '094.White_breasted_Nuthatch', '095.Baltimore_Oriole', '096.Hooded_Oriole', '097.Orchard_Oriole', '098.Scott_Oriole', '099.Ovenbird', '100.Brown_Pelican', '101.White_Pelican', '102.Western_Wood_Pewee', '103.Sayornis', '104.American_Pipit', '105.Whip_poor_Will', '106.Horned_Puffin', '107.Common_Raven', '108.White_necked_Raven', '109.American_Redstart', '110.Geococcyx', '111.Loggerhead_Shrike', '112.Great_Grey_Shrike', '113.Baird_Sparrow', '114.Black_throated_Sparrow', '115.Brewer_Sparrow', '116.Chipping_Sparrow', '117.Clay_colored_Sparrow', '118.House_Sparrow', '119.Field_Sparrow', '120.Fox_Sparrow', '121.Grasshopper_Sparrow', '122.Harris_Sparrow', '123.Henslow_Sparrow', '124.Le_Conte_Sparrow', '125.Lincoln_Sparrow', '126.Nelson_Sharp_tailed_Sparrow', '127.Savannah_Sparrow', '128.Seaside_Sparrow', '129.Song_Sparrow', '130.Tree_Sparrow', '131.Vesper_Sparrow', '132.White_crowned_Sparrow', '133.White_throated_Sparrow', '134.Cape_Glossy_Starling', '135.Bank_Swallow', '136.Barn_Swallow', '137.Cliff_Swallow', '138.Tree_Swallow', '139.Scarlet_Tanager', '140.Summer_Tanager', '141.Artic_Tern', '142.Black_Tern', '143.Caspian_Tern', '144.Common_Tern', '145.Elegant_Tern', '146.Forsters_Tern', '147.Least_Tern', '148.Green_tailed_Towhee', '149.Brown_Thrasher', '150.Sage_Thrasher', '151.Black_capped_Vireo', '152.Blue_headed_Vireo', '153.Philadelphia_Vireo', '154.Red_eyed_Vireo', '155.Warbling_Vireo', '156.White_eyed_Vireo', '157.Yellow_throated_Vireo', '158.Bay_breasted_Warbler', '159.Black_and_white_Warbler', '160.Black_throated_Blue_Warbler', '161.Blue_winged_Warbler', '162.Canada_Warbler', '163.Cape_May_Warbler', '164.Cerulean_Warbler', '165.Chestnut_sided_Warbler', '166.Golden_winged_Warbler', '167.Hooded_Warbler', '168.Kentucky_Warbler', '169.Magnolia_Warbler', '170.Mourning_Warbler', '171.Myrtle_Warbler', '172.Nashville_Warbler', '173.Orange_crowned_Warbler', '174.Palm_Warbler', '175.Pine_Warbler', '176.Prairie_Warbler', '177.Prothonotary_Warbler', '178.Swainson_Warbler', '179.Tennessee_Warbler', '180.Wilson_Warbler', '181.Worm_eating_Warbler', '182.Yellow_Warbler', '183.Northern_Waterthrush', '184.Louisiana_Waterthrush', '185.Bohemian_Waxwing', '186.Cedar_Waxwing', '187.American_Three_toed_Woodpecker', '188.Pileated_Woodpecker', '189.Red_bellied_Woodpecker', '190.Red_cockaded_Woodpecker', '191.Red_headed_Woodpecker', '192.Downy_Woodpecker', '193.Bewick_Wren', '194.Cactus_Wren', '195.Carolina_Wren', '196.House_Wren', '197.Marsh_Wren', '198.Rock_Wren', '199.Winter_Wren', '200.Common_Yellowthroat']\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "class_names = train_data.classes\n",
    "print(class_names)\n",
    "num_classes = len(class_names)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import timm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'vit_base_patch16_224'\n",
    "model = timm.create_model(model_name, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([1, 1, 768])\n",
      "pos_embed torch.Size([1, 197, 768])\n",
      "patch_embed.proj.weight torch.Size([768, 3, 16, 16])\n",
      "patch_embed.proj.bias torch.Size([768])\n",
      "blocks.0.norm1.weight torch.Size([768])\n",
      "blocks.0.norm1.bias torch.Size([768])\n",
      "blocks.0.attn.qkv.weight torch.Size([2304, 768])\n",
      "blocks.0.attn.qkv.bias torch.Size([2304])\n",
      "blocks.0.attn.proj.weight torch.Size([768, 768])\n",
      "blocks.0.attn.proj.bias torch.Size([768])\n",
      "blocks.0.norm2.weight torch.Size([768])\n",
      "blocks.0.norm2.bias torch.Size([768])\n",
      "blocks.0.mlp.fc1.weight torch.Size([3072, 768])\n",
      "blocks.0.mlp.fc1.bias torch.Size([3072])\n",
      "blocks.0.mlp.fc2.weight torch.Size([768, 3072])\n",
      "blocks.0.mlp.fc2.bias torch.Size([768])\n",
      "blocks.1.norm1.weight torch.Size([768])\n",
      "blocks.1.norm1.bias torch.Size([768])\n",
      "blocks.1.attn.qkv.weight torch.Size([2304, 768])\n",
      "blocks.1.attn.qkv.bias torch.Size([2304])\n",
      "blocks.1.attn.proj.weight torch.Size([768, 768])\n",
      "blocks.1.attn.proj.bias torch.Size([768])\n",
      "blocks.1.norm2.weight torch.Size([768])\n",
      "blocks.1.norm2.bias torch.Size([768])\n",
      "blocks.1.mlp.fc1.weight torch.Size([3072, 768])\n",
      "blocks.1.mlp.fc1.bias torch.Size([3072])\n",
      "blocks.1.mlp.fc2.weight torch.Size([768, 3072])\n",
      "blocks.1.mlp.fc2.bias torch.Size([768])\n",
      "blocks.2.norm1.weight torch.Size([768])\n",
      "blocks.2.norm1.bias torch.Size([768])\n",
      "blocks.2.attn.qkv.weight torch.Size([2304, 768])\n",
      "blocks.2.attn.qkv.bias torch.Size([2304])\n",
      "blocks.2.attn.proj.weight torch.Size([768, 768])\n",
      "blocks.2.attn.proj.bias torch.Size([768])\n",
      "blocks.2.norm2.weight torch.Size([768])\n",
      "blocks.2.norm2.bias torch.Size([768])\n",
      "blocks.2.mlp.fc1.weight torch.Size([3072, 768])\n",
      "blocks.2.mlp.fc1.bias torch.Size([3072])\n",
      "blocks.2.mlp.fc2.weight torch.Size([768, 3072])\n",
      "blocks.2.mlp.fc2.bias torch.Size([768])\n",
      "blocks.3.norm1.weight torch.Size([768])\n",
      "blocks.3.norm1.bias torch.Size([768])\n",
      "blocks.3.attn.qkv.weight torch.Size([2304, 768])\n",
      "blocks.3.attn.qkv.bias torch.Size([2304])\n",
      "blocks.3.attn.proj.weight torch.Size([768, 768])\n",
      "blocks.3.attn.proj.bias torch.Size([768])\n",
      "blocks.3.norm2.weight torch.Size([768])\n",
      "blocks.3.norm2.bias torch.Size([768])\n",
      "blocks.3.mlp.fc1.weight torch.Size([3072, 768])\n",
      "blocks.3.mlp.fc1.bias torch.Size([3072])\n",
      "blocks.3.mlp.fc2.weight torch.Size([768, 3072])\n",
      "blocks.3.mlp.fc2.bias torch.Size([768])\n",
      "blocks.4.norm1.weight torch.Size([768])\n",
      "blocks.4.norm1.bias torch.Size([768])\n",
      "blocks.4.attn.qkv.weight torch.Size([2304, 768])\n",
      "blocks.4.attn.qkv.bias torch.Size([2304])\n",
      "blocks.4.attn.proj.weight torch.Size([768, 768])\n",
      "blocks.4.attn.proj.bias torch.Size([768])\n",
      "blocks.4.norm2.weight torch.Size([768])\n",
      "blocks.4.norm2.bias torch.Size([768])\n",
      "blocks.4.mlp.fc1.weight torch.Size([3072, 768])\n",
      "blocks.4.mlp.fc1.bias torch.Size([3072])\n",
      "blocks.4.mlp.fc2.weight torch.Size([768, 3072])\n",
      "blocks.4.mlp.fc2.bias torch.Size([768])\n",
      "blocks.5.norm1.weight torch.Size([768])\n",
      "blocks.5.norm1.bias torch.Size([768])\n",
      "blocks.5.attn.qkv.weight torch.Size([2304, 768])\n",
      "blocks.5.attn.qkv.bias torch.Size([2304])\n",
      "blocks.5.attn.proj.weight torch.Size([768, 768])\n",
      "blocks.5.attn.proj.bias torch.Size([768])\n",
      "blocks.5.norm2.weight torch.Size([768])\n",
      "blocks.5.norm2.bias torch.Size([768])\n",
      "blocks.5.mlp.fc1.weight torch.Size([3072, 768])\n",
      "blocks.5.mlp.fc1.bias torch.Size([3072])\n",
      "blocks.5.mlp.fc2.weight torch.Size([768, 3072])\n",
      "blocks.5.mlp.fc2.bias torch.Size([768])\n",
      "blocks.6.norm1.weight torch.Size([768])\n",
      "blocks.6.norm1.bias torch.Size([768])\n",
      "blocks.6.attn.qkv.weight torch.Size([2304, 768])\n",
      "blocks.6.attn.qkv.bias torch.Size([2304])\n",
      "blocks.6.attn.proj.weight torch.Size([768, 768])\n",
      "blocks.6.attn.proj.bias torch.Size([768])\n",
      "blocks.6.norm2.weight torch.Size([768])\n",
      "blocks.6.norm2.bias torch.Size([768])\n",
      "blocks.6.mlp.fc1.weight torch.Size([3072, 768])\n",
      "blocks.6.mlp.fc1.bias torch.Size([3072])\n",
      "blocks.6.mlp.fc2.weight torch.Size([768, 3072])\n",
      "blocks.6.mlp.fc2.bias torch.Size([768])\n",
      "blocks.7.norm1.weight torch.Size([768])\n",
      "blocks.7.norm1.bias torch.Size([768])\n",
      "blocks.7.attn.qkv.weight torch.Size([2304, 768])\n",
      "blocks.7.attn.qkv.bias torch.Size([2304])\n",
      "blocks.7.attn.proj.weight torch.Size([768, 768])\n",
      "blocks.7.attn.proj.bias torch.Size([768])\n",
      "blocks.7.norm2.weight torch.Size([768])\n",
      "blocks.7.norm2.bias torch.Size([768])\n",
      "blocks.7.mlp.fc1.weight torch.Size([3072, 768])\n",
      "blocks.7.mlp.fc1.bias torch.Size([3072])\n",
      "blocks.7.mlp.fc2.weight torch.Size([768, 3072])\n",
      "blocks.7.mlp.fc2.bias torch.Size([768])\n",
      "blocks.8.norm1.weight torch.Size([768])\n",
      "blocks.8.norm1.bias torch.Size([768])\n",
      "blocks.8.attn.qkv.weight torch.Size([2304, 768])\n",
      "blocks.8.attn.qkv.bias torch.Size([2304])\n",
      "blocks.8.attn.proj.weight torch.Size([768, 768])\n",
      "blocks.8.attn.proj.bias torch.Size([768])\n",
      "blocks.8.norm2.weight torch.Size([768])\n",
      "blocks.8.norm2.bias torch.Size([768])\n",
      "blocks.8.mlp.fc1.weight torch.Size([3072, 768])\n",
      "blocks.8.mlp.fc1.bias torch.Size([3072])\n",
      "blocks.8.mlp.fc2.weight torch.Size([768, 3072])\n",
      "blocks.8.mlp.fc2.bias torch.Size([768])\n",
      "blocks.9.norm1.weight torch.Size([768])\n",
      "blocks.9.norm1.bias torch.Size([768])\n",
      "blocks.9.attn.qkv.weight torch.Size([2304, 768])\n",
      "blocks.9.attn.qkv.bias torch.Size([2304])\n",
      "blocks.9.attn.proj.weight torch.Size([768, 768])\n",
      "blocks.9.attn.proj.bias torch.Size([768])\n",
      "blocks.9.norm2.weight torch.Size([768])\n",
      "blocks.9.norm2.bias torch.Size([768])\n",
      "blocks.9.mlp.fc1.weight torch.Size([3072, 768])\n",
      "blocks.9.mlp.fc1.bias torch.Size([3072])\n",
      "blocks.9.mlp.fc2.weight torch.Size([768, 3072])\n",
      "blocks.9.mlp.fc2.bias torch.Size([768])\n",
      "blocks.10.norm1.weight torch.Size([768])\n",
      "blocks.10.norm1.bias torch.Size([768])\n",
      "blocks.10.attn.qkv.weight torch.Size([2304, 768])\n",
      "blocks.10.attn.qkv.bias torch.Size([2304])\n",
      "blocks.10.attn.proj.weight torch.Size([768, 768])\n",
      "blocks.10.attn.proj.bias torch.Size([768])\n",
      "blocks.10.norm2.weight torch.Size([768])\n",
      "blocks.10.norm2.bias torch.Size([768])\n",
      "blocks.10.mlp.fc1.weight torch.Size([3072, 768])\n",
      "blocks.10.mlp.fc1.bias torch.Size([3072])\n",
      "blocks.10.mlp.fc2.weight torch.Size([768, 3072])\n",
      "blocks.10.mlp.fc2.bias torch.Size([768])\n",
      "blocks.11.norm1.weight torch.Size([768])\n",
      "blocks.11.norm1.bias torch.Size([768])\n",
      "blocks.11.attn.qkv.weight torch.Size([2304, 768])\n",
      "blocks.11.attn.qkv.bias torch.Size([2304])\n",
      "blocks.11.attn.proj.weight torch.Size([768, 768])\n",
      "blocks.11.attn.proj.bias torch.Size([768])\n",
      "blocks.11.norm2.weight torch.Size([768])\n",
      "blocks.11.norm2.bias torch.Size([768])\n",
      "blocks.11.mlp.fc1.weight torch.Size([3072, 768])\n",
      "blocks.11.mlp.fc1.bias torch.Size([3072])\n",
      "blocks.11.mlp.fc2.weight torch.Size([768, 3072])\n",
      "blocks.11.mlp.fc2.bias torch.Size([768])\n",
      "norm.weight torch.Size([768])\n",
      "norm.bias torch.Size([768])\n",
      "head.weight torch.Size([200, 768])\n",
      "head.bias torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'generator' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m      2\u001b[0m     param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'generator' has no len()"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "for param in model.head.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 85952456\n",
      "Trainable parameters: 153800\n",
      "Frozen parameters: 85798656\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "frozen_params = total_params - trainable_params\n",
    "\n",
    "print(f'Total parameters: {total_params}')\n",
    "print(f'Trainable parameters: {trainable_params}')\n",
    "print(f'Frozen parameters: {frozen_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()   \n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 4.4347 Acc: 0.1623\n",
      "val Loss: 3.3686 Acc: 0.3994\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 2.6611 Acc: 0.5383\n",
      "val Loss: 2.1796 Acc: 0.6221\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 1.7800 Acc: 0.6999\n",
      "val Loss: 1.6333 Acc: 0.7139\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 1.3316 Acc: 0.7819\n",
      "val Loss: 1.3315 Acc: 0.7468\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 1.0711 Acc: 0.8224\n",
      "val Loss: 1.1530 Acc: 0.7697\n",
      "\n",
      "Best val Acc: 0.769653\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, criterion):\n",
    "    model.eval()  \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    total_loss = running_loss / dataset_sizes['test']\n",
    "    total_acc = running_corrects.double() / dataset_sizes['test']\n",
    "\n",
    "    print(f'Test Loss: {total_loss:.4f} Acc: {total_acc:.4f}')\n",
    "\n",
    "    return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.1378 Acc: 0.7717\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_model(model_ft, dataloaders['test'], criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), 'fine_tuned_vit_1lf_5e.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
